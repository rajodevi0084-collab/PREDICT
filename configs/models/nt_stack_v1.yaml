stack:
  teacher_seq:
    type: "tcn"
    lookback: 128
    channels: 128
    blocks: 4
    kernel: 5
    dropout: 0.1
    weight_decay: 1e-4
    heads:
      cls: {loss: "focal", gamma: 1.5, alpha: "balanced"}
      reg: {loss: "huber", delta: "median*1.5"}
  tabular_lgbm:
    reg:
      objective: "huber"
      learning_rate: 0.05
      max_depth: 8
      num_leaves: 64
      n_estimators: 2000
      subsample: 0.8
      colsample_bytree: 0.8
      min_child_samples: 80
    cls:
      objective: "binary_logloss_3way"  # internal wrapper for {-1,0,1}
      learning_rate: 0.05
      max_depth: 8
      n_estimators: 1500
      class_weight: "balanced"
      label_smoothing: 0.05
  blender:
    type: "ridge"
    inputs: ["teacher_seq.cls","teacher_seq.reg","tabular_lgbm.cls","tabular_lgbm.reg"]
    weight_metric: "mae_inverse"
calibration:
  cls: "temperature"
  reg: "linear"
conformal:
  enabled: true
  coverage: 0.9
latency_budget_ms: 5
